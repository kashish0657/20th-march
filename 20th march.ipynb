{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809e5dd1-f8df-48bf-bd1b-bda7302a2ccd",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING Assignment (20th MARCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842a50f-a0cc-46f5-a413-33497aa8e80d",
   "metadata": {},
   "source": [
    "## Q:1:- What is data encoding ? How is it useful in data science ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d2e00-85f8-45c8-bb9c-55ff225cf9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "    Data encoding is the process of converting data from one format or \n",
    "    representation to another. In the context of data science, encoding \n",
    "    is particularly important when dealing with categorical variables, \n",
    "    as many machine learning algorithms and statistical models require\n",
    "    numerical inputs. Categorical variables are variables that can take\n",
    "    on a limited and fixed number of distinct values, such as gender \n",
    "    (male or female), color (red, blue, green), or country (USA, UK, Canada).\n",
    "    \n",
    "Data encoding is essential in data science for several reasons:\n",
    "\n",
    "Algorithm Compatibility: Many machine learning algorithms and statistical\n",
    "models require numerical inputs. By encoding categorical variables, you can \n",
    "ensure that your data can be fed into these algorithms.\n",
    "\n",
    "Handling Categorical Data: Encoding allows you to represent categorical data\n",
    "effectively, enabling you to analyze and extract insights from this type of information.\n",
    "\n",
    "Preventing Bias: Some algorithms might inadvertently introduce bias when dealing\n",
    "with categorical variables. Proper encoding techniques help mitigate this issue.\n",
    "\n",
    "Dimensionality Reduction: Certain encoding methods, like binary encoding, can\n",
    "reduce the dimensionality of data while still preserving useful information.\n",
    "\n",
    "Enhancing Predictive Performance: Encoding data accurately can lead to improved\n",
    "model performance and more reliable predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80692b-32be-49d5-a876-eb8f7071b67c",
   "metadata": {},
   "source": [
    "## Q:2:- What is nominal encoding ? Provide an example of how you would use it in a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a812fa-db00-4cb2-b165-986cc1b963a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "Nominal encoding, also known as one-hot encoding or dummy encoding, is\n",
    "a method used in data preprocessing to convert categorical variables\n",
    "into a numerical representation. In nominal encoding, each unique \n",
    "category in a categorical variable is converted into a binary vector,\n",
    "where each element represents the presence or absence of a particular \n",
    "category.\n",
    "\n",
    "Let's explain nominal encoding with an example:\n",
    "\n",
    "Suppose you have a dataset of fruits, and one of the categorical features\n",
    "is \"Color,\" which can take values like \"Red,\" \"Green,\" and \"Yellow.\"\n",
    "\n",
    "Original dataset:\n",
    "\n",
    "Fruit\tColor\n",
    "Apple\tRed\n",
    "Banana\tYellow\n",
    "Grape\tGreen\n",
    "Pear\tGreen\n",
    "Orange\tOrange\n",
    "To use this data in a machine learning algorithm, you need to convert the\n",
    "categorical variable \"Color\" into numerical form using nominal encoding.\n",
    "Here's how it works:\n",
    "\n",
    "Identify the unique categories in the \"Color\" column: [\"Red\", \"Green\", \"Yellow\", \"Orange\"].\n",
    "\n",
    "Create binary vectors for each unique category:\n",
    "\n",
    "Color\tRed\tGreen\tYellow\tOrange\n",
    "Red\t1\t0\t0\t0\n",
    "Green\t0\t1\t0\t0\n",
    "Yellow\t0\t0\t1\t0\n",
    "Green\t0\t1\t0\t0\n",
    "Orange\t0\t0\t0\t1\n",
    "In the nominal encoding, only one element in each row is 1, representing\n",
    "the presence of that particular category, while all others are 0.\n",
    "\n",
    "By using nominal encoding, you can transform the categorical data into a\n",
    "format that machine learning algorithms can understand, as most algorithms \n",
    "require numerical inputs. In this case, you can use the binary vectors for \n",
    "\"Color\" as features to train a classifier that predicts the fruit type\n",
    "based on its color.\n",
    "\n",
    "Real-world scenario:\n",
    "\n",
    "Let's say you're working on a customer churn prediction problem for a\n",
    "telecom company. One of the important features in your dataset is \n",
    "\"Internet Service Type,\" which can take values like \"DSL,\" \"Fiber Optic,\"\n",
    "and \"No Internet Service.\" Since machine learning models need numerical inputs,\n",
    "you can apply nominal encoding to convert this categorical feature into a\n",
    "numerical representation.\n",
    "\n",
    "Original dataset:\n",
    "\n",
    "Customer ID\tInternet Service Type\n",
    "1\tDSL\n",
    "2\tFiber Optic\n",
    "3\tNo Internet Service\n",
    "4\tDSL\n",
    "5\tFiber Optic\n",
    "After nominal encoding:\n",
    "\n",
    "Internet Service Type\tDSL\tFiber Optic\tNo Internet Service\n",
    "DSL\t1\t0\t0\n",
    "Fiber Optic\t0\t1\t0\n",
    "No Internet Service\t0\t0\t1\n",
    "DSL\t1\t0\t0\n",
    "Fiber Optic\t0\t1\t0\n",
    "Now, you can use these encoded binary vectors as features to train a machine learning\n",
    "model to predict customer churn based on their internet service type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf73c41-c937-419d-a034-b612a161c181",
   "metadata": {},
   "source": [
    "## Q:3:- In what situation is nominal encoding preferred over one-hot encoding ? Provide a practical example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b9ec3-208b-4c8c-ae9b-71c9ff1664ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "Nominal encoding is preferred over one-hot encoding when dealing with \n",
    "categorical variables that have a large number of distinct categories.\n",
    "One-hot encoding creates a binary feature for each category, resulting\n",
    "in a very high-dimensional and sparse dataset. This can lead to a\n",
    "significant increase in memory usage and computation time, especially\n",
    "when working with large datasets.\n",
    "\n",
    "Practical Example:\n",
    "Let's consider a dataset containing information about customer transactions\n",
    "in an e-commerce platform. One of the categorical features in the dataset is\n",
    "\"Product Category,\" which represents the category of the product purchased.\n",
    "This feature may have numerous distinct categories, such as \"Electronics,\"\n",
    "\"Clothing,\" \"Home & Garden,\" \"Sports & Outdoors,\" \"Toys,\" \"Books,\" and so on.\n",
    "\n",
    "If we were to use one-hot encoding for this feature, we would create a binary\n",
    "column for each product category, resulting in a wide dataset with many columns.\n",
    "This could be highly inefficient and computationally expensive, especially if\n",
    "the e-commerce platform has a vast product inventory with thousands of distinct\n",
    "categories.\n",
    "\n",
    "In such cases, nominal encoding (also known as integer encoding) would be \n",
    "preferred. With nominal encoding, each unique category is represented by a \n",
    "unique integer value. For instance:\n",
    "\n",
    "Electronics: 1\n",
    "Clothing: 2\n",
    "Home & Garden: 3\n",
    "Sports & Outdoors: 4\n",
    "Toys: 5\n",
    "Books: 6\n",
    "By using nominal encoding, we reduce the dimensionality of the categorical\n",
    "feature, making the dataset more compact and easier to work with. It is\n",
    "essential to note that this approach should be used when there is no inherent\n",
    "ordinal relationship between the categories, as nominal encoding treats all\n",
    "categories equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2557c7b-3ac3-4b13-9243-e0e8afae0239",
   "metadata": {},
   "source": [
    "## Q:4:- Suppose you have a dataset containing categorical data wth 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31b0d9-9672-4112-a904-0ffd6648dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "When dealing with categorical data, one common encoding technique used\n",
    "to transform the data into a format suitable for machine learning \n",
    "algorithms is \"One-Hot Encoding.\" Given that you have a dataset with \n",
    "five unique categorical values, let's understand why One-Hot Encoding \n",
    "is a suitable choice:\n",
    "\n",
    "One-Hot Encoding:\n",
    "One-Hot Encoding is a process of converting categorical data into a binary\n",
    "representation. For each unique category in the dataset, a new binary feature\n",
    "(dummy variable) is created. The binary feature is set to 1 when the data\n",
    "belongs to that category and 0 otherwise. Essentially, it \"one-hot\" encodes\n",
    "each category into a vector representation.\n",
    "\n",
    "Example:\n",
    "Suppose you have a categorical feature \"Color\" with five unique values: Red,\n",
    "Blue, Green, Yellow, and Orange. After applying One-Hot Encoding, the feature\n",
    "would be transformed into five binary features: \"Color_Red,\" \"Color_Blue,\"\n",
    "\"Color_Green,\" \"Color_Yellow,\" and \"Color_Orange.\"\n",
    "\n",
    "Reasoning for One-Hot Encoding:\n",
    "\n",
    "Preservation of Information: One-Hot Encoding avoids introducing ordinality or\n",
    "magnitude assumptions among categorical values. Since there is no inherent order \n",
    "or hierarchy among the colors (Red is not greater or smaller than Blue), One-Hot\n",
    "Encoding appropriately captures the individual categories' distinctness.\n",
    "\n",
    "Preventing Numerical Misinterpretation: If you were to use integer encoding \n",
    "(assigning integers 1 to 5 to represent the five colors), machine learning \n",
    "algorithms might mistakenly interpret the numerical relationship between the\n",
    "categories (e.g., Orange (5) is greater than Red (1)), leading to incorrect\n",
    "model behavior.\n",
    "\n",
    "Handling Algorithms: Most machine learning algorithms expect numerical input,\n",
    "and One-Hot Encoding allows categorical data to be appropriately processed. \n",
    "Many algorithms, like regression or gradient-based methods, require continuous\n",
    "input features, making One-Hot Encoding essential.\n",
    "\n",
    "Interpretability and Transparency: One-Hot Encoding makes it easier to interpret\n",
    "the impact of each categorical value on the model's output. Each binary feature\n",
    "acts as a flag representing the presence or absence of a specific category, \n",
    "contributing to the model's decision.\n",
    "\n",
    "However, it's important to note that One-Hot Encoding might lead to a significant\n",
    "increase in the dataset's dimensionality, especially if you have a large number\n",
    "of unique categories. In such cases, you may need to consider other encoding \n",
    "techniques like \"Label Encoding\" or \"Target Encoding\" \n",
    "(also known as \"Mean Encoding\" or \"Likelihood Encoding\") that can handle high\n",
    "cardinality categorical features more efficiently. But, for a dataset with only \n",
    "five unique categorical values, One-Hot Encoding is a suitable choice given\n",
    "its advantages and simplicity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c7c5e-922d-467e-adbb-d9f0fe47534d",
   "metadata": {},
   "source": [
    "## Q:5:- In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data , how many new columns would be created? Show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f881fd-70f8-48ee-998a-2b59c14b6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "In nominal encoding, we create new binary columns for each unique category\n",
    "in the original categorical columns. For each row, the binary column \n",
    "corresponding to the category will have a value of 1 if the category is\n",
    "present and 0 if it is not.\n",
    "\n",
    "Let's say the first categorical column has m unique categories, and the second\n",
    "categorical column has n unique categories.\n",
    "\n",
    "For the first categorical column, we will create m new binary columns, and for\n",
    "the second categorical column, we will create n new binary columns.\n",
    "\n",
    "Therefore, the total number of new columns created will be:\n",
    "\n",
    "Total new columns = Number of binary columns for the first categorical column\n",
    "+ Number of binary columns for the second categorical column\n",
    "Total new columns = m + n\n",
    "\n",
    "Now, you mentioned that the dataset has 1000 rows and 5 columns, and two of \n",
    "those columns are categorical. So, you have 2 categorical columns and\n",
    "5 - 2 = 3 numerical columns.\n",
    "\n",
    "Without knowing the exact number of unique categories in each categorical\n",
    "column, we cannot determine the values of m and n. So, let's consider\n",
    "hypothetical values for m and n:\n",
    "\n",
    "Suppose the first categorical column has 4 unique categories (m = 4) and \n",
    "the second categorical column has 5 unique categories (n = 5).\n",
    "\n",
    "Total new columns = m + n\n",
    "Total new columns = 4 + 5\n",
    "Total new columns = 9\n",
    "\n",
    "In this case, using nominal encoding, you would create 9 new columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f97b74-9871-4bfe-b6f1-2d95f3fff7b9",
   "metadata": {},
   "source": [
    "## Q:6:- You are working with dataset containing information about different types of animals, including their species, habitat,and diet. Which encoding technique would you use to transform the categorical data into a format suitable for machine learning algorithms? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b32d36-2f34-46ee-baf2-1d73055bd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "To transform categorical data into a format suitable for machine\n",
    "learning algorithms, I would use the one-hot encoding technique.\n",
    "One-hot encoding is a popular method for converting categorical\n",
    "variables into numerical representations, which can be easily used\n",
    "as input for machine learning models. Here's why I would choose\n",
    "one-hot encoding and its justification:\n",
    "\n",
    "Preservation of Distances: One-hot encoding preserves the distinct\n",
    "categories and doesn't introduce any ordinal relationship between\n",
    "them. Each category is represented as a binary vector with a \"1\" in\n",
    "the corresponding category and \"0\" in all other categories. This \n",
    "ensures that there is no artificial numerical relationship between\n",
    "different categories, which could lead to incorrect assumptions\n",
    "during model training.\n",
    "\n",
    "Handling of Non-Ordinal Data: In the animal dataset, attributes like \n",
    "\"species,\" \"habitat,\" and \"diet\" are non-ordinal categorical variables,\n",
    "meaning there's no inherent order or ranking among the categories. \n",
    "One-hot encoding is ideal for such data since it avoids assigning numerical\n",
    "values that might imply a relationship between the categories.\n",
    "\n",
    "Elimination of Bias: Using label encoding or ordinal encoding \n",
    "(where categories are assigned integer values) could inadvertently\n",
    "introduce bias into the model. The numerical values might be \n",
    "misinterpreted by the model as having a meaningful relationship,\n",
    "leading to biased predictions. One-hot encoding ensures each category\n",
    "is represented independently, eliminating the possibility of such bias.\n",
    "\n",
    "Compatibility with Machine Learning Algorithms: Many machine learning \n",
    "algorithms, including most linear models and tree-based models, require\n",
    "numerical inputs. One-hot encoding allows these algorithms to interpret\n",
    "and use categorical data effectively.\n",
    "\n",
    "Interpretability: One-hot encoding makes the data representation more\n",
    "interpretable for humans as well. Each category becomes a separate binary\n",
    "feature, and its presence or absence is easy to understand and analyze.\n",
    "\n",
    "Of course, it's important to consider the size of the dataset and the\n",
    "number of unique categories within each categorical attribute, as \n",
    "one-hot encoding can significantly increase the dimensionality of the\n",
    "feature space. In some cases, feature reduction techniques like feature\n",
    "selection or feature extraction may be necessary to manage this high\n",
    "dimensionality. But overall, one-hot encoding remains a powerful and \n",
    "commonly used method to transform categorical data into a suitable\n",
    "format for machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f68c8a-6327-4203-a935-4b48fba868c3",
   "metadata": {},
   "source": [
    "## Q:7:- You are working a project that involves predicting customer churnfor a telecommunications company. You have a dataset with 5 features , including the customer's gender , age , contract type , monthly charges , and tenure. Which encoding technique(s) would you use to transform the categorical data into numerical data ? Provide a step-by-step explaination and how you would implement the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775e821-a602-4aa8-93b7-c8690123f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:-\n",
    "To transform the categorical data into numerical data, we can use \n",
    "one-hot encoding for the \"gender\" and \"contract type\" features and\n",
    "keep the numerical features as they are. Here's a step-by-step \n",
    "explanation of how to implement the encoding:\n",
    "\n",
    "Step 1: Understanding the dataset\n",
    "Let's first understand the dataset and its structure:\n",
    "\n",
    "Gender: Categorical feature with values like \"Male\" and \"Female.\"\n",
    "Age: Numerical feature representing the customer's age.\n",
    "Contract Type: Categorical feature with values like \"Month-to-month,\n",
    "\" \"One-year,\" and \"Two-year.\"\n",
    "Monthly Charges: Numerical feature representing the customer's monthly\n",
    "charges.\n",
    "Tenure: Numerical feature representing the customer's tenure in months\n",
    "(how long they have been a customer).\n",
    "Step 2: One-hot encoding for categorical features\n",
    "One-hot encoding is used to convert categorical variables into binary\n",
    "vectors. For each unique value in the categorical feature, a new binary column is created.\n",
    "\n",
    "In our case, we'll use one-hot encoding for the \"gender\" and\n",
    "\"contract type\" features:\n",
    "\n",
    "a. Gender:\n",
    "\n",
    "Original values: \"Male\" and \"Female.\"\n",
    "After one-hot encoding:\n",
    "Male: 1 if the customer is male, 0 otherwise.\n",
    "Female: 1 if the customer is female, 0 otherwise.\n",
    "b. Contract Type:\n",
    "\n",
    "Original values: \"Month-to-month,\" \"One-year,\" and \"Two-year.\"\n",
    "After one-hot encoding:\n",
    "Month-to-month: 1 if the customer has a month-to-month contract, 0 otherwise.\n",
    "One-year: 1 if the customer has a one-year contract, 0 otherwise.\n",
    "Two-year: 1 if the customer has a two-year contract, 0 otherwise.\n",
    "Step 3: Handling numerical features\n",
    "The numerical features, \"age,\" \"monthly charges,\" and \"tenure,\" are\n",
    "already in a numerical format, so we don't need any further encoding for them.\n",
    "\n",
    "Step 4: Implementing the encoding\n",
    "To implement the encoding in Python, you can use libraries like Pandas or Scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d248b67-2505-4f35-93c1-11d953438c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is stored in a DataFrame called 'data'\n",
    "# Step 2: One-hot encoding\n",
    "data = pd.get_dummies(data, columns=['gender', 'contract_type'])\n",
    "\n",
    "# Step 3: No further encoding required for numerical features\n",
    "\n",
    "# Now your dataset is ready for modeling, and you can use it for predicting customer churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66984b9c-5f8e-4b2c-a589-89306dd3bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is stored in a DataFrame called 'data'\n",
    "# Step 2: One-hot encoding\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)  # drop='first' to avoid multicollinearity\n",
    "encoded_columns = encoder.fit_transform(data[['gender', 'contract_type']])\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names(['gender', 'contract_type']))\n",
    "\n",
    "# Concatenate the encoded_df with the original data\n",
    "data_encoded = pd.concat([data, encoded_df], axis=1)\n",
    "data_encoded.drop(['gender', 'contract_type'], axis=1, inplace=True)\n",
    "\n",
    "# Step 3: No further encoding required for numerical features\n",
    "\n",
    "# Now your dataset is ready for modeling, and you can use it for predicting customer churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d86f1-9219-45d3-a6c0-10e9510915d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa3bed-1740-4f2e-a065-4bdc78215444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cef813-7355-48bc-8d54-2fc0859cc1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de6e97-5542-4f4b-b12e-b870e1ecd5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb970178-3527-4c5c-8515-7d08f17d22c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8dd43-e728-44c5-8539-625dc0ef2b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
